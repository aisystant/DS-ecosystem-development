# Единое хранилище знаний (Memory Bank): Три архитектурных варианта

Этот документ предлагает три альтернативных архитектуры для централизованного memory bank — единой точки истины для всей экосистемы развития интеллекта.

> **Статус:** Draft
> **Дата:** 2025-11-12
> **Автор:** Архитектор экосистемы

---

## TL;DR (150–250 слов)

Экосистеме нужен **единый memory bank** как фундамент для всех операций: управление знаниями, цифровые двойники участников, транзакции, траектории развития, артефакты и агенты. Без него невозможны персонализация (ИИ-проводник), экономика вклада (токеномика) и масштабирование сообщества.

**Три парадигмы решения:**

1. **Docs-first / Git-native** — эволюция текущего Obsidian+Git подхода. Знания = документы в Markdown, версионирование через Git, автоматизация через GitHub Actions. Минимальные инвестиции, быстрый старт, но ограничения при структурированных запросах и сложной аналитике.

2. **Data-first / Lakehouse+Graph** — централизованное хранилище с разделением: озеро данных (события, транзакции, логи) + граф знаний (онтология, связи, двойники) + документы (руководства). Мощные запросы, семантический поиск, аналитика, но требует инфраструктуры и миграции.

3. **Twin/Ledger-first** — блокчейн-ориентированный подход с цифровыми двойниками на распределённом реестре. Максимальная прозрачность вклада, портативность профилей, но высокая сложность и стоимость операций.

**Критерий выбора:** баланс между скоростью внедрения, стоимостью владения, гибкостью развития и требованиями к согласованности данных. Для текущей стадии (MVP → Product-Market Fit) рекомендуется **гибридный старт** с Docs-first + постепенным добавлением структурированных слоёв.

---

## Вариант 1: Docs-first / Git-native

### Идея (1–2 абзаца)

Расширяем текущую архитектуру `content/` + Obsidian + Git как **single source of truth**. Все знания, руководства, онтология, даже профили двойников — это Markdown-документы с YAML frontmatter. Git обеспечивает версионирование, PR/ревью — контроль качества, GitHub Actions — автоматизацию (lint, классификация, генерация derived-артефактов).

Структурированные данные (транзакции, события, метрики) хранятся в отдельных файлах JSON/CSV/SQLite в той же Git-репе или внешней БД с синхронизацией через скрипты. Семантический поиск реализуется через векторные индексы (Pinecone/Weaviate) с периодической переиндексацией.

### Структура хранилища

```
ecosystem-memory/
├── content/                           # Curated зона (только через PR)
│   ├── 0-governance/                  # Управление, планы, решения
│   ├── 1-philosophy/                  # Идеи, принципы, манифесты
│   ├── 2-promotion/                   # Маркетинг, материалы
│   ├── 3-knowledge/                   # Библиотека знаний
│   │   ├── ontology/                  # Мета-понятия, глоссарий
│   │   │   ├── meta-meta.md           # Верхний уровень абстракций
│   │   │   ├── meta-concepts.md       # Мета-понятия
│   │   │   └── domain-concepts/       # Понятия по доменам
│   │   ├── guides/                    # Руководства по программам
│   │   │   ├── personal/              # Личное развитие
│   │   │   ├── professional/          # Рабочее развитие
│   │   │   └── research/              # Исследовательское
│   │   └── programs/                  # Программы развития
│   ├── 4-systems/                     # Документация подсистем
│   └── 5-profiles/                    # Публичные профили участников
│       └── digital-twins/             # Цифровые двойники (шаблоны)
│           └── {participant-id}.md    # Профиль с параметрами
│
├── derived/                           # Derived зона (только автогенерация)
│   ├── analytics/                     # Дашборды, отчёты
│   ├── indexes/                       # Поисковые индексы
│   │   ├── vector-embeddings/         # Векторные представления
│   │   └── search-indexes/            # BM25, полнотекст
│   ├── summaries/                     # Автосаммари документов
│   └── lineage/                       # Граф зависимостей документов
│
├── data-vault/                        # Сборник текущих данных (data commons)
│   ├── events/                        # События системы
│   │   ├── learning-events.jsonl      # Обучение (артефакты, ревью)
│   │   ├── economic-events.jsonl      # Транзакции (токены, фиат)
│   │   ├── agent-events.jsonl         # Действия агентов
│   │   └── community-events.jsonl     # Взаимодействия сообщества
│   ├── exports/                       # Экспорты из внешних систем
│   │   ├── club-platform/             # Выгрузки с клубной платформы
│   │   ├── crm/                       # Лиды, контакты, сделки
│   │   └── chat-logs/                 # Логи чатов (анонимизированные)
│   ├── metrics/                       # Метрики и телеметрия
│   │   ├── digital-twins-metrics.csv  # Параметры двойников (срезы)
│   │   ├── trajectories.csv           # Прогресс по траекториям
│   │   └── epistemic-status.csv       # Эпистемический статус
│   └── transactions/                  # Финансовые операции
│       ├── token-ledger.jsonl         # Движение токенов
│       ├── fiat-payments.csv          # Фиатные платежи
│       └── wallets.json               # Кошельки участников
│
├── artifacts/                         # Артефакты участников
│   ├── assignments/                   # Выполненные задания
│   ├── projects/                      # Проекты
│   └── agents/                        # Созданные агенты
│       └── {agent-id}/                # Манифест + код + логи
│
├── .github/
│   └── workflows/                     # CI/CD пайплайны
│       ├── classify-docs.yml          # Классификация документов
│       ├── validate-frontmatter.yml   # Валидация метаданных
│       ├── backup.yml                 # Резервное копирование
│       └── index-vectors.yml          # Векторная индексация
│
├── ops/                               # Операционные скрипты
│   ├── ingest/                        # Импорт данных
│   │   ├── import-club-data.py        # Выгрузка с платформы
│   │   └── sync-crm.py                # Синхронизация CRM
│   ├── normalize/                     # Нормализация и валидация
│   ├── index/                         # Индексация и поиск
│   │   ├── build-vector-index.py      # Векторный поиск
│   │   └── build-graph.py             # Граф связей
│   └── backup/                        # Бэкапы и ретенция
│       ├── backup-to-s3.sh            # AWS S3 бэкап
│       └── retention-policy.json      # Политики хранения
│
└── adr/                               # Architecture Decision Records
    ├── 001-git-as-source-of-truth.md
    ├── 002-curated-vs-derived.md
    └── 003-data-vault-structure.md
```

### Потоки работы (5–7 шагов)

**1. Ingestion (Пополнение)**
- Ручное: автор создаёт Markdown через Obsidian/редактор, коммитит в feature-ветку
- Автоматическое: скрипты `ops/ingest/` забирают данные из внешних систем (CRM, клуб, чаты) → `data-vault/exports/`

**2. Нормализация и валидация**
- GitHub Actions проверяет frontmatter (обязательные поля, типы значений)
- Линтеры проверяют структуру Markdown, наличие обязательных разделов
- Классификация документов (скрипт `ops/classify_documents.py`) назначает теги
- Для structured data: валидация JSON Schema

**3. Версионирование и ADR**
- Все изменения проходят через PR с mandatory review (для `content/`)
- Архитектурные решения фиксируются в `adr/`
- Git-теги для релизов знаний (например, `ontology-v2.1`)

**4. Индексация и поиск**
- **Вектор**: `ops/index/build-vector-index.py` создаёт embeddings (OpenAI/Cohere) → Pinecone/Weaviate
- **BM25**: полнотекстовый индекс для точного поиска терминов
- **Граф**: `build-graph.py` анализирует ссылки `[[...]]` → Neo4j/SQLite для навигации

**5. Публикация и контракты**
- `derived/` автогенерируется агентами: саммари, аналитика, индексы
- API-шлюз (REST/GraphQL) предоставляет доступ к данным для внешних сервисов
- Экспорт срезов для обучения ИИ-моделей (fine-tuning)

**6. Контроль качества**
- Чек-листы качества для разных типов документов (руководства, понятия, ADR)
- Периодический аудит непротиворечивости (скрипт проверяет циклические зависимости понятий)
- Метрики: coverage онтологии, актуальность (last-updated), использование (views)

**7. Бэкапы и ретенция**
- **Перед операциями**: автоматический snapshot в S3 (GitHub Actions hook)
- **Расписание**: ежедневные инкрементальные + еженедельные полные бэкапы
- **Retention**: 30 дней daily, 12 месяцев weekly, вечное хранение тегированных версий
- **Восстановление**: `ops/backup/restore.sh` с выбором точки времени

### Где живут и как версионируются

| Сущность | Расположение | Версионирование | Формат |
|----------|--------------|-----------------|--------|
| **Онтология/глоссарий** | `content/3-knowledge/ontology/` | Git PR + review, семантические версии | Markdown + YAML frontmatter |
| **Профили двойников** | `content/5-profiles/digital-twins/{id}.md` | Git, но чаще обновления → синхронизация с БД | Markdown (публичное) + JSON в `data-vault/` (приватное) |
| **Руководства/ДЗ** | `content/3-knowledge/guides/` | Git PR, мажорные версии при изменении структуры | Markdown с вложенными заданиями |
| **События/журналы** | `data-vault/events/*.jsonl` | Append-only лог, ротация по месяцам | JSONL (JSON Lines) |
| **Транзакции/кошельки** | `data-vault/transactions/` | Append-only + периодические снепшоты балансов | JSONL + CSV для балансов |
| **Артефакты агентов** | `artifacts/agents/{id}/` | Git для манифестов, S3 для больших файлов/моделей | Манифест JSON + код + логи |

### Интеграции и агенты

**Базовые действия (Apps SDK Actions):**

1. **`query_knowledge`** — семантический/полнотекстовый поиск по knowledge base
   ```yaml
   action: query_knowledge
   params:
     query: "системная грамотность"
     search_type: semantic | keyword | hybrid
     filters: { section: ontology, status: approved }
   ```

2. **`get_twin_profile`** — получить профиль цифрового двойника
   ```yaml
   action: get_twin_profile
   params:
     twin_id: "participant-123"
     include: [goals, trajectory, artifacts, metrics]
   ```

3. **`log_event`** — записать событие в data vault
   ```yaml
   action: log_event
   params:
     event_type: learning | economic | agent | community
     payload: { artifact_id, task_id, result, timestamp }
   ```

4. **`create_artifact`** — создать артефакт участника
   ```yaml
   action: create_artifact
   params:
     twin_id: "participant-123"
     artifact_type: assignment | project | agent
     content: "..."
     metadata: { program, guide_step }
   ```

5. **`update_trajectory`** — обновить траекторию развития двойника
   ```yaml
   action: update_trajectory
   params:
     twin_id: "participant-123"
     stage: student | intellectual | professional | researcher | enlightener
     evidence: [artifact_id_1, artifact_id_2]
   ```

6. **`transaction_log`** — записать транзакцию (токены/фиат)
   ```yaml
   action: transaction_log
   params:
     from_wallet: "wallet-123"
     to_wallet: "wallet-456"
     amount: 100.0
     currency: token | rub | usd
     reason: payment_for_service | reward | split
   ```

7. **`sync_external_source`** — синхронизировать данные из внешнего источника
   ```yaml
   action: sync_external_source
   params:
     source: club_platform | crm | chat_logs
     since: "2025-11-01T00:00:00Z"
     destination: data-vault/exports/{source}/
   ```

**Шлюз к внешним источникам:**
- **MCP Tools**: коннекторы к CRM (Bitrix24/amoCRM), клубной платформе, Solana RPC
- **Webhooks**: входящие события от внешних систем → `data-vault/events/`
- **Export API**: REST/GraphQL для чтения знаний и профилей внешними агентами

### Trade-offs (3–5 пунктов)

**Плюсы:**
- ✅ **Минимальные инвестиции**: используем существующую инфраструктуру (Git, GitHub, Obsidian)
- ✅ **Знакомые инструменты**: команда уже работает с Markdown, Git, Python
- ✅ **Прозрачность изменений**: Git-история = аудит-лог для знаний
- ✅ **Гибкость структуры**: легко добавлять новые разделы, рефакторить

**Минусы:**
- ❌ **Ограниченные запросы**: сложные JOIN-ы, аггрегации требуют скриптов/ETL
- ❌ **Производительность поиска**: полнотекстовый поиск по Git-репе медленный без индексов
- ❌ **Дублирование данных**: двойники и в `content/`, и в `data-vault/` — нужна синхронизация
- ❌ **Масштабируемость**: Git не рассчитан на миллионы файлов/коммитов (но до 100k документов ок)

### Когда выбирать (критерии)

- ✅ Команда < 20 человек, MVP/early stage
- ✅ Большая часть данных — документы/руководства/онтология
- ✅ Обновления знаний редкие (раз в неделю/месяц), не real-time
- ✅ Важна простота онбординга новых участников (Markdown понятен всем)
- ✅ Бюджет ограничен, нужно быстро запуститься

---

## Вариант 2: Data-first / Lakehouse+Graph

### Идея (1–2 абзаца)

Централизуем данные в **многослойной архитектуре**: озеро данных (data lake) для сырых событий/логов/экспортов, граф знаний (knowledge graph) для онтологии и связей, реляционная БД для структурированных сущностей (профили, транзакции), документы в object storage (S3) с метаданными в каталоге. Единая шина событий (Kafka/Pulsar) связывает все подсистемы.

**Single source of truth** — это комбинация источников с чёткими контрактами: события → data lake → ETL → warehouses/graph → serving layer (API/search). Версионирование через immutable logs + снепшоты витрин данных. Семантический поиск, аналитика, персонализация работают напрямую с БД/графом без генерации промежуточных файлов.

### Структура хранилища

```
Lakehouse Architecture:

┌─────────────────────────────────────────────────────────────┐
│                   SERVING LAYER (API Gateway)               │
│  REST/GraphQL API, Vector Search, Analytics Dashboard       │
└─────────────────────────────────────────────────────────────┘
                            ▲
                            │
┌─────────────────────────────────────────────────────────────┐
│                    PROCESSING LAYER                          │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐     │
│  │  ETL Jobs    │  │   ML Models  │  │   Indexers   │     │
│  │ (Airflow/DBT)│  │  (Training)  │  │ (Embeddings) │     │
│  └──────────────┘  └──────────────┘  └──────────────┘     │
└─────────────────────────────────────────────────────────────┘
                            ▲
                            │
┌─────────────────────────────────────────────────────────────┐
│                     STORAGE LAYER                            │
│  ┌────────────────┐  ┌────────────────┐  ┌──────────────┐  │
│  │  Data Lake     │  │ Knowledge Graph│  │ Relational DB│  │
│  │  (S3/MinIO)    │  │   (Neo4j)      │  │ (PostgreSQL) │  │
│  │                │  │                │  │              │  │
│  │ • Raw events   │  │ • Ontology     │  │ • Profiles   │  │
│  │ • Logs         │  │ • Concepts     │  │ • Wallets    │  │
│  │ • Exports      │  │ • Relations    │  │ • Txns       │  │
│  │ • Documents    │  │ • Trajectories │  │ • Artifacts  │  │
│  └────────────────┘  └────────────────┘  └──────────────┘  │
│                                                              │
│  ┌────────────────┐  ┌────────────────┐                    │
│  │ Vector Store   │  │  Time Series   │                    │
│  │ (Pinecone/     │  │  (InfluxDB/    │                    │
│  │  Weaviate)     │  │   TimescaleDB) │                    │
│  │                │  │                │                    │
│  │ • Embeddings   │  │ • Metrics      │                    │
│  │ • Semantic     │  │ • Telemetry    │                    │
│  │   search       │  │ • Status time  │                    │
│  └────────────────┘  └────────────────┘                    │
└─────────────────────────────────────────────────────────────┘
                            ▲
                            │
┌─────────────────────────────────────────────────────────────┐
│                   INGESTION LAYER                            │
│  ┌────────────────────────────────────────────────────────┐ │
│  │  Event Bus (Kafka / Pulsar)                            │ │
│  │  Topics: learning, economic, agent, community, system  │ │
│  └────────────────────────────────────────────────────────┘ │
│                                                              │
│  Producers: Club Platform, CRM, Apps, Agents, Web/Mobile   │
└─────────────────────────────────────────────────────────────┘
```

**Схема данных (примеры таблиц/коллекций):**

```sql
-- PostgreSQL Tables

digital_twins (
  id UUID PRIMARY KEY,
  participant_id UUID,
  stage VARCHAR,  -- student, intellectual, professional, researcher, enlightener
  created_at TIMESTAMP,
  updated_at TIMESTAMP,
  metadata JSONB  -- 50+ параметров: интересы, навыки, цели, ритмы
)

trajectories (
  id UUID PRIMARY KEY,
  twin_id UUID REFERENCES digital_twins(id),
  program_type VARCHAR,  -- personal, professional, research
  current_guide_id VARCHAR,
  current_step INT,
  progress_pct FLOAT,
  started_at TIMESTAMP,
  last_activity_at TIMESTAMP
)

artifacts (
  id UUID PRIMARY KEY,
  twin_id UUID,
  artifact_type VARCHAR,  -- assignment, project, agent
  content TEXT,
  metadata JSONB,
  created_at TIMESTAMP,
  reviewed_by UUID,
  review_score FLOAT
)

wallets (
  id UUID PRIMARY KEY,
  participant_id UUID,
  balance_tokens DECIMAL,
  balance_fiat_rub DECIMAL,
  created_at TIMESTAMP
)

transactions (
  id UUID PRIMARY KEY,
  from_wallet UUID,
  to_wallet UUID,
  amount DECIMAL,
  currency VARCHAR,
  reason VARCHAR,
  tx_hash VARCHAR,  -- для on-chain транзакций
  timestamp TIMESTAMP
)

epistemic_status (
  twin_id UUID PRIMARY KEY,
  reputation_score FLOAT,
  artifacts_count INT,
  reviews_count INT,
  usage_by_others INT,
  last_updated TIMESTAMP,
  status_history JSONB  -- массив изменений статуса
)
```

**Neo4j Graph Schema:**

```cypher
(:Concept {id, name, level, definition})
  -[:DEPENDS_ON]-> (:Concept)
  -[:PART_OF]-> (:Concept)

(:Guide {id, title, program_type})
  -[:HAS_STEP]-> (:Step {order, title, content})
  -[:REQUIRES]-> (:Concept)

(:DigitalTwin {id, stage})
  -[:ENROLLED_IN]-> (:Program)
  -[:MASTERED]-> (:Concept)
  -[:CREATED]-> (:Artifact)
  -[:AT_STEP]-> (:Step)

(:Participant)
  -[:HAS_TWIN]-> (:DigitalTwin)
  -[:MENTORS]-> (:Participant)
  -[:COLLABORATES_WITH]-> (:Participant)
```

### Потоки работы (5–7 шагов)

**1. Ingestion (Пополнение)**
- События поступают на Kafka topics (`learning`, `economic`, `agent`, `community`)
- Consumers записывают сырые события в Data Lake (S3 в Parquet/Avro)
- Batch imports из внешних систем (CRM, клуб) через ETL-джобы (Airflow)

**2. Нормализация и валидация**
- Stream processing (Flink/Spark Streaming) валидирует события по JSON Schema
- Обогащение: lookup профилей, резолвинг ID, дедупликация
- Запись normalized events в staging слой Data Lake

**3. Версионирование и ADR**
- Онтология и концепции версионируются в Neo4j (свойство `version`, history nodes)
- Immutable event log — версионирование неявное через timestamp
- Снепшоты витрин данных (PostgreSQL) делаются ежедневно → S3

**4. Индексация и поиск**
- **Вектор**: ETL-джоб генерирует embeddings из документов/концептов → Weaviate
- **BM25**: PostgreSQL full-text search (tsvector) для точного поиска
- **Граф**: Neo4j обеспечивает навигацию по связям концептов/траекторий

**5. Публикация и контракты**
- **API Gateway** (GraphQL/REST) предоставляет унифицированный доступ
- Контракты API документированы в OpenAPI/GraphQL schema
- SDK для агентов: Python/TypeScript клиенты с типизацией

**6. Контроль качества**
- Data quality checks (Great Expectations): completeness, uniqueness, referential integrity
- Monitoring дашборды (Grafana): задержки ETL, покрытие онтологии, gaps в событиях
- Автоматические алерты при аномалиях (например, резкое падение числа артефактов)

**7. Бэкапы и ретенции**
- Data Lake: AWS S3 versioning + lifecycle policies (архив в Glacier через 90 дней)
- PostgreSQL: pg_dump ежедневно + PITR (Point-in-Time Recovery) через WAL
- Neo4j: снепшоты графа раз в неделю
- Retention: горячие данные 30 дней, теплые 1 год, холодные вечно (архив)

### Где живут и как версионируются

| Сущность | Расположение | Версионирование | Формат |
|----------|--------------|-----------------|--------|
| **Онтология/глоссарий** | Neo4j graph + S3 (документы) | Version property в nodes, immutable history nodes | Nodes + Markdown в S3 |
| **Профили двойников** | PostgreSQL `digital_twins` + metadata JSONB | Updated_at + audit log таблица | JSON в БД |
| **Руководства/ДЗ** | S3 + метаданные в PostgreSQL `guides` | Version колонка + S3 versioning | Markdown в S3, мета в БД |
| **События/журналы** | Kafka → S3 Data Lake (Parquet партиции по дате) | Immutable append-only | Parquet/Avro |
| **Транзакции/кошельки** | PostgreSQL `transactions`, `wallets` | Append-only txns + balance snapshots | Relational |
| **Артефакты агентов** | S3 + PostgreSQL `artifacts` (мета) | S3 versioning + created_at | Files в S3, мета в БД |

### Интеграции и агенты

**Базовые действия (Apps SDK Actions) — те же 7, но реализация через API:**

1. `query_knowledge` → GraphQL к API Gateway → Weaviate (semantic) + PostgreSQL (keyword)
2. `get_twin_profile` → REST API → PostgreSQL join с trajectories, artifacts
3. `log_event` → Kafka Producer → топик соответствующего типа
4. `create_artifact` → REST API → PostgreSQL insert + S3 upload
5. `update_trajectory` → REST API → PostgreSQL update + Neo4j update (граф траектории)
6. `transaction_log` → Kafka Producer → economic topic → PostgreSQL + on-chain sync
7. `sync_external_source` → Airflow trigger → ETL DAG

**Дополнительно:**

8. **`graph_query`** — Cypher-запросы к Neo4j для сложной навигации
   ```yaml
   action: graph_query
   params:
     cypher: "MATCH (t:DigitalTwin {id: $twin_id})-[:AT_STEP]->(s:Step) RETURN s"
     parameters: { twin_id: "..." }
   ```

9. **`analytics_query`** — SQL/BI запросы к витринам данных
   ```yaml
   action: analytics_query
   params:
     query: "SELECT stage, COUNT(*) FROM digital_twins GROUP BY stage"
   ```

10. **`ml_inference`** — вызов ML-модели (рекомендации, предсказание траектории)
    ```yaml
    action: ml_inference
    params:
      model: trajectory_recommender
      input: { twin_id, current_step, goals }
    ```

**Шлюз к внешним источникам:**
- MCP Tools работают через API Gateway (те же эндпоинты)
- Webhooks пишут в Kafka → обрабатываются как обычные события
- Внешние агенты получают API keys с rate limits и scope permissions

### Trade-offs (3–5 пунктов)

**Плюсы:**
- ✅ **Мощные запросы**: JOIN-ы, аггрегации, графовая навигация — нативно
- ✅ **Масштабируемость**: миллионы событий/день, сотни тысяч профилей
- ✅ **Аналитика в реальном времени**: stream processing + OLAP витрины
- ✅ **Семантический поиск**: векторная БД для персонализации ИИ-проводника
- ✅ **Чёткие контракты**: API схемы, data quality tests, observability

**Минусы:**
- ❌ **Высокая сложность**: требует DevOps/DataOps экспертизы (Kafka, Airflow, Neo4j, etc.)
- ❌ **Инфраструктурные затраты**: ~$1000-2000/мес на AWS (managed services) или on-prem сервера
- ❌ **Миграция**: нужно перенести текущие Markdown-документы в новую структуру
- ❌ **Vendor lock-in**: зависимость от конкретных БД/сервисов (сложнее сменить стек)
- ❌ **Длинный time-to-market**: 2-3 месяца на разработку и отладку инфраструктуры

### Когда выбирать (критерии)

- ✅ Команда > 50 участников, активная разработка и данных > 1GB/день
- ✅ Критичны сложные запросы: рекомендации, аналитика, ML
- ✅ Real-time персонализация (ИИ-проводник) — ключевая функция
- ✅ Есть Data Engineer/DevOps в команде или бюджет на инфраструктуру
- ✅ Планируется масштабирование до тысяч активных участников

---

## Вариант 3: Twin/Ledger-first (Blockchain-ориентированный)

### Идея (1–2 абзаца)

Цифровые двойники — это **NFT на блокчейне** (Solana/Polygon) с on-chain идентификаторами и критическими атрибутами (стадия, статус, баланс токенов), остальные данные — в IPFS/Arweave (immutable storage). Каждое значимое действие (создание артефакта, смена стадии, начисление токенов) — это on-chain транзакция или событие. Траектории развития и вклад полностью аудируемы и портативны (участник может «забрать» свой двойник в другую экосистему).

Знания (онтология, руководства) хранятся в IPFS с CID-ссылками в смарт-контрактах. Токеномика встроена в ядро: все начисления/вестинг/сплиты — on-chain программы (Solana Programs/Ethereum Smart Contracts). **Single source of truth** — это блокчейн + decentralized storage, off-chain БД используется только для кэширования и быстрого доступа.

### Структура хранилища

```
Blockchain + Decentralized Storage Architecture:

┌─────────────────────────────────────────────────────────────┐
│                   APPLICATION LAYER                          │
│  Web3 App (React + wagmi/web3.js), ИИ-проводник, Агенты    │
└─────────────────────────────────────────────────────────────┘
                            ▲
                            │
┌─────────────────────────────────────────────────────────────┐
│                   INDEXER & CACHE LAYER                      │
│  ┌────────────────┐  ┌────────────────┐                    │
│  │  The Graph     │  │ PostgreSQL     │                    │
│  │  (Subgraphs)   │  │ (Cache/Reads)  │                    │
│  │                │  │                │                    │
│  │ • Index events │  │ • Twin profiles│                    │
│  │ • Query on-    │  │ • Artifacts    │                    │
│  │   chain state  │  │ • Leaderboards │                    │
│  └────────────────┘  └────────────────┘                    │
└─────────────────────────────────────────────────────────────┘
                            ▲
                            │
┌─────────────────────────────────────────────────────────────┐
│                   BLOCKCHAIN LAYER (L1/L2)                   │
│  ┌────────────────────────────────────────────────────────┐ │
│  │  Solana / Polygon / Ethereum L2                        │ │
│  │                                                         │ │
│  │  Smart Contracts / Programs:                           │ │
│  │  • DigitalTwinNFT (mint, update stage, burn)          │ │
│  │  • TokenEconomy (mint, transfer, vest, burn)          │ │
│  │  • ArtifactRegistry (register, attest, reward)        │ │
│  │  • TrajectoryManager (enroll, complete, upgrade)      │ │
│  │  • EpistemicStatusOracle (reputation updates)         │ │
│  └────────────────────────────────────────────────────────┘ │
│                                                              │
│  On-chain Events:                                            │
│  • TwinCreated(id, owner, stage, timestamp)                │
│  • ArtifactSubmitted(twinId, artifactCID, taskId)          │
│  • StageUpgraded(twinId, from, to, evidence)               │
│  • TokensEarned(twinId, amount, reason)                    │
│  • ReputationUpdated(twinId, score, timestamp)             │
└─────────────────────────────────────────────────────────────┘
                            ▲
                            │
┌─────────────────────────────────────────────────────────────┐
│              DECENTRALIZED STORAGE LAYER                     │
│  ┌────────────────┐  ┌────────────────┐  ┌──────────────┐  │
│  │  IPFS/Filecoin │  │   Arweave      │  │  Ceramic     │  │
│  │                │  │                │  │  (Data       │  │
│  │ • Guides       │  │ • Ontology     │  │   Streams)   │  │
│  │ • Artifacts    │  │ • Manuals      │  │              │  │
│  │ • Agent code   │  │ • History logs │  │ • Mutable    │  │
│  │ (mutable via   │  │ (永久 immut.)  │  │   profiles   │  │
│  │  IPNS/MFS)     │  │                │  │              │  │
│  └────────────────┘  └────────────────┘  └──────────────┘  │
│                                                              │
│  CID References stored in Smart Contracts:                  │
│  DigitalTwin.profileCID -> ipfs://Qm...                     │
│  Guide.contentCID -> ar://abc123...                         │
└─────────────────────────────────────────────────────────────┘
```

**Smart Contract Schemas (примеры):**

```solidity
// Solidity (или Rust для Solana)

contract DigitalTwinNFT {
  struct Twin {
    uint256 tokenId;
    address owner;
    Stage stage;         // 0=Student, 1=Intellectual, ...
    string profileCID;   // IPFS CID профиля (50+ параметров)
    uint256 createdAt;
    uint256 updatedAt;
    uint256 reputationScore;
  }

  mapping(uint256 => Twin) public twins;

  function mint(address to, string memory profileCID) external;
  function updateStage(uint256 tokenId, Stage newStage, string[] memory evidenceCIDs) external;
  function updateProfileCID(uint256 tokenId, string memory newCID) external;
}

contract ArtifactRegistry {
  struct Artifact {
    bytes32 id;
    uint256 twinId;
    string contentCID;    // IPFS CID артефакта
    uint256 taskId;
    bool reviewed;
    uint8 score;          // 0-100
    uint256 timestamp;
  }

  mapping(bytes32 => Artifact) public artifacts;

  function submit(uint256 twinId, string memory contentCID, uint256 taskId) external;
  function review(bytes32 artifactId, uint8 score) external;
}

contract TokenEconomy {
  // ERC20/SPL Token с дополнительной логикой

  function earn(address recipient, uint256 amount, string reason) external;
  function vest(address recipient, uint256 amount, uint256 unlockTime) external;
  function split(uint256 amount, address[] memory recipients, uint256[] memory shares) external;
}
```

### Потоки работы (5–7 шагов)

**1. Ingestion (Пополнение)**
- Участник создаёт артефакт → загружает в IPFS → получает CID
- Вызывает `ArtifactRegistry.submit(twinId, CID, taskId)` → on-chain транзакция
- Данные из внешних систем (CRM, клуб): off-chain bot заливает в IPFS → регистрирует CID в контракте

**2. Нормализация и валидация**
- Smart contract валидирует права доступа (владелец Twin NFT = вызывающий)
- Структурированные данные проверяются off-chain перед загрузкой в IPFS (JSON Schema)
- On-chain только критические атрибуты, полная информация — в IPFS по CID

**3. Версионирование и ADR**
- IPFS CID = естественное версионирование (immutable content addressing)
- История изменений двойника: последовательность on-chain событий `TwinUpdated`
- Для mutable данных: IPNS (мутабельный указатель на CID) или Ceramic Streams

**4. Индексация и поиск**
- **The Graph**: subgraph индексирует on-chain события → GraphQL API
- **Off-chain cache**: PostgreSQL синхронизируется с блокчейном через event listener
- **Семантический поиск**: векторизация контента из IPFS → Weaviate (off-chain)

**5. Публикация и контракты**
- Public API: читает из The Graph + cache PostgreSQL
- Write операции: Web3 транзакции через кошелёк участника (MetaMask/Phantom)
- Агенты работают через Web3 SDK (ethers.js / @solana/web3.js)

**6. Контроль качества**
- On-chain: смарт-контракты проверяют инварианты (например, stage upgrade только с доказательствами)
- Off-chain: линтеры проверяют структуру данных перед загрузкой в IPFS
- Peer review: наставник вызывает `ArtifactRegistry.review()` → on-chain подтверждение

**7. Бэкапы и ретенция**
- IPFS pinning services (Pinata, Infura) обеспечивают доступность
- Arweave — вечное хранение критических данных (онтология, ключевые руководства)
- Blockchain: полная история в блоках, не требует бэкапов (но archive nodes дороги)
- Off-chain cache: обычные pg_dump бэкапы PostgreSQL

### Где живут и как версионируются

| Сущность | Расположение | Версионирование | Формат |
|----------|--------------|-----------------|--------|
| **Онтология/глоссарий** | Arweave (immutable) + CID в контракте | Новая версия = новый CID, старые доступны вечно | JSON-LD в Arweave |
| **Профили двойников** | IPFS (profileCID) + on-chain критические поля | IPNS для mutable, история через blockchain events | JSON в IPFS |
| **Руководства/ДЗ** | IPFS/Arweave + CID в контракте `Guide` | Версии = разные CID, контракт может указывать "latest" | Markdown/JSON в IPFS |
| **События/журналы** | Blockchain events + The Graph index | Immutable on-chain log | Contract events |
| **Транзакции/кошельки** | On-chain (native chain transactions) | Blockchain ledger | Native chain format |
| **Артефакты агентов** | IPFS (код + манифест) + CID в `ArtifactRegistry` | Immutable CID, fork = новый CID | Files в IPFS |

### Интеграции и агенты

**Базовые действия (Apps SDK Actions) — через Web3:**

1. **`query_knowledge`** → GraphQL к The Graph subgraph + fetch IPFS CID
   ```javascript
   const guide = await contract.guides(guideId);
   const content = await ipfs.cat(guide.contentCID);
   ```

2. **`get_twin_profile`** → Контракт `DigitalTwinNFT.twins(tokenId)` + fetch profileCID
   ```javascript
   const twin = await twinContract.twins(tokenId);
   const profile = await ipfs.cat(twin.profileCID);
   ```

3. **`log_event`** → Emit on-chain event через смарт-контракт
   ```javascript
   await contract.logLearningEvent(twinId, taskId, resultCID);
   ```

4. **`create_artifact`** → Upload to IPFS → `ArtifactRegistry.submit()`
   ```javascript
   const cid = await ipfs.add(artifact);
   await artifactRegistry.submit(twinId, cid, taskId);
   ```

5. **`update_trajectory`** → `TrajectoryManager.completeStep()` on-chain
   ```javascript
   await trajectoryManager.completeStep(twinId, stepId, evidenceCIDs);
   ```

6. **`transaction_log`** → Native chain transfer (SOL/ETH) или token transfer
   ```javascript
   await tokenContract.transfer(toAddress, amount);
   ```

7. **`sync_external_source`** → Off-chain bot: fetch data → upload IPFS → register CID
   ```javascript
   const data = await fetchFromCRM();
   const cid = await ipfs.add(JSON.stringify(data));
   await registryContract.registerExternalData(source, cid);
   ```

**Дополнительно:**

8. **`verify_on_chain`** — верифицировать подпись/proof on-chain
9. **`delegate_action`** — делегировать права действия (через Account Abstraction)
10. **`cross_chain_bridge`** — перенос токенов/NFT между чейнами

**Шлюз к внешним источникам:**
- Chainlink Oracles для off-chain данных (цены фиата, API вызовы)
- HTTPS oracles (e.g., Chainlink Functions) для чтения из веба
- Webhooks → off-chain relayer → on-chain транзакция

### Trade-offs (3–5 пунктов)

**Плюсы:**
- ✅ **Максимальная прозрачность**: весь вклад аудируем on-chain
- ✅ **Портативность**: участник владеет Twin NFT, может использовать в других dApps
- ✅ **Автоматическая токеномика**: смарт-контракты выполняют сплиты/вестинг без посредников
- ✅ **Цензуроустойчивость**: IPFS/Arweave не могут быть "выключены"
- ✅ **Композируемость**: другие проекты могут интегрировать ваши контракты

**Минусы:**
- ❌ **Высокая стоимость операций**: каждая транзакция = gas fees (~$0.01-1 на Solana, $1-50 на Ethereum)
- ❌ **Сложность разработки**: Web3 экспертиза, аудит смарт-контрактов ($10k-50k)
- ❌ **Производительность**: блокчейн медленнее БД (Solana ~400ms финализация, Ethereum ~12s)
- ❌ **UX барьер**: пользователи должны иметь кошельки, понимать gas, подтверждать транзакции
- ❌ **Регуляторные риски**: KYC/AML для токенов, классификация как security

### Когда выбирать (критерии)

- ✅ Токеномика — ядро бизнес-модели, важна прозрачность начислений
- ✅ Портативность профилей критична (участники могут использовать Twin в других экосистемах)
- ✅ Команда имеет Web3 экспертизу или готова инвестировать в обучение
- ✅ Аудитория знакома с криптовалютами, имеет кошельки
- ✅ Планируется сообщество contributors (разработчики создают агенты/плагины с монетизацией)

---

## Сводная таблица сравнения

| Критерий | Docs-first / Git-native | Data-first / Lakehouse+Graph | Twin/Ledger-first |
|----------|-------------------------|------------------------------|-------------------|
| **Скорость пополнения** | 🟢 Быстрая (Markdown в редакторе) | 🟡 Средняя (API/формы → ETL) | 🔴 Медленная (Web3 UX, gas) |
| **Согласованность данных** | 🟡 Средняя (синхронизация Git ↔ БД) | 🟢 Высокая (транзакции БД, ACID) | 🟢 Высокая (on-chain финализация) |
| **Масштабируемость** | 🟡 До 100k документов | 🟢 Миллионы записей | 🟡 Ограничена throughput блокчейна |
| **Стоимость владения** | 🟢 Низкая (~$50-200/мес) | 🔴 Высокая ($1k-5k/мес) | 🔴 Очень высокая ($2k-10k/мес + gas) |
| **Простота онбординга** | 🟢 Markdown знают все | 🟡 Нужно API понимание | 🔴 Требует Web3 грамотности |
| **Контроль доступа** | 🟢 Git permissions + CODEOWNERS | 🟢 Row-level security, API keys | 🟡 On-chain permissions (сложнее) |
| **Пригодность для персонализации** | 🟡 Требует индексов (векторы) | 🟢 Native vector search + граф | 🟡 Off-chain cache нужен |
| **Обучение ИИ** | 🟢 Markdown → embeddings легко | 🟢 ETL в training data, ML pipelines | 🟡 Fetch из IPFS, дороже |
| **Аналитика** | 🔴 Требует скриптов/ETL | 🟢 Native OLAP, BI инструменты | 🟡 The Graph + off-chain aggregations |
| **Транзакции и токеномика** | 🔴 Off-chain БД, нет прозрачности | 🟡 PostgreSQL, аудит логи | 🟢 Native on-chain, полная прозрачность |
| **Портативность профилей** | 🔴 Привязка к репе | 🔴 Привязка к БД | 🟢 Twin NFT = переносимый |
| **Время до MVP** | 🟢 1-2 недели | 🔴 2-3 месяца | 🔴 3-6 месяцев |
| **Сложность поддержки** | 🟢 Низкая (Git + Python) | 🔴 Высокая (Kafka, Airflow, Neo4j) | 🔴 Очень высокая (Web3, смарт-контракты) |
| **Vendor lock-in** | 🟢 Минимальный (Git everywhere) | 🟡 Средний (specific БД) | 🟢 Открытые протоколы (blockchain, IPFS) |
| **Резервное копирование** | 🟢 Git = natural backup | 🟢 Стандартные БД dumps | 🟡 Blockchain не требует, но IPFS pinning |

**Легенда:**
🟢 Отлично / Низко
🟡 Средне / Умеренно
🔴 Плохо / Высоко

---

## Рекомендация и следующие 3 шага

### Рекомендуемый подход: **Гибридный старт с Docs-first + постепенная эволюция**

**Обоснование:**

На текущей стадии (MVP → Product-Market Fit) критичны **скорость итераций** и **низкая стоимость владения**. Команда уже работает с Git/Obsidian, есть рабочие скрипты классификации и автоматизации. Полная миграция на Lakehouse или Blockchain — overkill и отвлечёт ресурсы от развития ключевых функций (ИИ-проводник, контент).

**Стратегия:**

1. **Фаза 1 (сейчас-3 месяца): Укрепить Docs-first**
   - Внедрить `data-vault/` для структурированных данных (события, транзакции)
   - Добавить векторный поиск (Weaviate self-hosted или Pinecone)
   - Улучшить автоматизацию: резервные копии, индексация, валидация

2. **Фаза 2 (3-12 месяцев): Гибридный слой**
   - Поднять PostgreSQL для профилей двойников и транзакций (быстрые запросы)
   - Синхронизация Git ↔ PostgreSQL через GitHub Actions
   - Neo4j для онтологии и траекторий (если нужны сложные графовые запросы)

3. **Фаза 3 (12+ месяцев): Опционально Blockchain**
   - Если токеномика станет ключевой и появится спрос на портативность профилей
   - Миграция критических данных (балансы, вклад) on-chain
   - Гибрид: on-chain ledger + off-chain storage для производительности

### Следующие 3 шага (конкретные действия)

**Шаг 1: Создать структуру `data-vault/` и первый ETL (1 неделя)**

- Создать директории `data-vault/events/`, `data-vault/transactions/`, `data-vault/exports/`
- Написать скрипт `ops/ingest/log_event.py` для записи событий в JSONL
- Интегрировать в текущие процессы: при создании артефакта → log в `learning-events.jsonl`

**Действие:**
```bash
# Создать структуру
mkdir -p data-vault/{events,transactions,exports,metrics}

# Написать скрипт логирования
cat > ops/ingest/log_event.py <<'EOF'
#!/usr/bin/env python3
import json
from datetime import datetime
from pathlib import Path

def log_event(event_type, payload):
    vault_dir = Path(__file__).parent.parent.parent / "data-vault/events"
    log_file = vault_dir / f"{event_type}-events.jsonl"

    event = {
        "timestamp": datetime.utcnow().isoformat(),
        "event_type": event_type,
        **payload
    }

    with open(log_file, "a") as f:
        f.write(json.dumps(event, ensure_ascii=False) + "\n")

if __name__ == "__main__":
    # Пример использования
    log_event("learning", {
        "twin_id": "participant-123",
        "action": "artifact_created",
        "artifact_id": "art-456",
        "task_id": "task-789"
    })
EOF

chmod +x ops/ingest/log_event.py
```

**Шаг 2: Внедрить векторный поиск для knowledge base (2 недели)**

- Выбрать vector store: Weaviate (self-hosted) или Pinecone (managed)
- Написать `ops/index/build-vector-index.py` для генерации embeddings из Markdown
- Создать простой API endpoint для семантического поиска

**Действие:**
```python
# ops/index/build-vector-index.py (псевдокод)
import weaviate
from openai import OpenAI

client_weaviate = weaviate.Client("http://localhost:8080")
client_openai = OpenAI()

# Индексация документов
for doc in content_docs:
    embedding = client_openai.embeddings.create(
        input=doc.content,
        model="text-embedding-ada-002"
    ).data[0].embedding

    client_weaviate.data_object.create({
        "content": doc.content,
        "path": doc.path,
        "metadata": doc.frontmatter
    }, "Document", vector=embedding)

# Поиск
def search_knowledge(query, limit=5):
    embedding = client_openai.embeddings.create(
        input=query,
        model="text-embedding-ada-002"
    ).data[0].embedding

    result = client_weaviate.query.get("Document", ["content", "path"]) \
        .with_near_vector({"vector": embedding}) \
        .with_limit(limit) \
        .do()

    return result
```

**Шаг 3: Разработать схему цифрового двойника и первый Apps SDK Action (2 недели)**

- Определить структуру YAML frontmatter для профилей двойников в `content/5-profiles/digital-twins/{id}.md`
- Создать JSON Schema для валидации 50+ параметров
- Реализовать `get_twin_profile` action в манифесте агента

**Действие:**
```yaml
# content/5-profiles/digital-twins/participant-123.md
---
twin_id: participant-123
participant_id: user-789
stage: student
created_at: 2025-11-01T10:00:00Z
updated_at: 2025-11-12T12:00:00Z

# 50+ параметров (пример)
profile:
  goals:
    - Освоить системное мышление
    - Создать первый проект
  interests:
    - Философия
    - Программирование
  skills:
    - Python: beginner
    - Системная грамотность: intermediate
  learning_style: visual
  weekly_commitment_hours: 10

trajectory:
  current_program: personal
  current_guide: fundamentals-of-thinking
  current_step: 3
  progress_pct: 15.0

metrics:
  artifacts_count: 5
  artifacts_reviewed: 3
  average_review_score: 8.5
  epistemic_status: 42.0

economy:
  wallet_id: wallet-123
  tokens_earned: 250.0
  tokens_spent: 50.0
  fiat_paid_rub: 5000.0
---

# Публичный профиль участника

Биография, достижения, публичные артефакты...
```

```json
// ops/schemas/digital-twin-schema.json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "required": ["twin_id", "participant_id", "stage", "profile", "trajectory"],
  "properties": {
    "twin_id": { "type": "string", "pattern": "^participant-[0-9]+$" },
    "stage": { "enum": ["student", "intellectual", "professional", "researcher", "enlightener"] },
    "profile": {
      "type": "object",
      "required": ["goals", "interests", "skills"],
      "properties": {
        "goals": { "type": "array", "items": { "type": "string" } },
        "interests": { "type": "array", "items": { "type": "string" } },
        "skills": { "type": "object" }
      }
    }
  }
}
```

---

## Self-Critique (Чек-лист рисков и пробелов)

**✅ Что учтено:**
- Три чётко разные парадигмы (Docs/Data/Ledger)
- Потоки работы и структура для каждого варианта
- Trade-offs и критерии выбора
- Конкретные следующие шаги

**⚠️ Риски и допущения:**

1. **Риск: Неполнота требований к цифровому двойнику**
   - Документ упоминает ">50 параметров", но не детализирует все
   - **Митигация**: нужен отдельный ADR с полной схемой двойника

2. **Риск: Производительность Git при росте**
   - Git не оптимизирован для миллионов файлов
   - **Митигация**: мониторинг размера репы, план миграции при >100k файлов

3. **Риск: Vendor lock-in в варианте 2**
   - Зависимость от Neo4j, Pinecone, конкретных AWS сервисов
   - **Митигация**: использовать open-source альтернативы (Weaviate вместо Pinecone) или контейнеризация

4. **Допущение: Токеномика уже спроектирована**
   - Документ описывает начисления/вестинг, но нет деталей алгоритма
   - **Нужно**: детальная спецификация правил начисления токенов

5. **Допущение: Есть бюджет на инфраструктуру**
   - Вариант 2 требует $1k-5k/мес, вариант 3 — ещё больше
   - **Нужно**: согласовать с финансовой стратегией

6. **Пробел: Интеграция с клубной платформой**
   - Нет деталей API/экспортов с текущей клубной платформы
   - **Нужно**: технический аудит текущих систем, доступные API

7. **Пробел: GDPR/персональные данные**
   - Хранение профилей участников требует compliance
   - **Нужно**: legal review, политика приватности, согласия пользователей

8. **Пробел: Обучение команды**
   - Вариант 2/3 требуют новых компетенций (DataOps, Web3)
   - **Нужно**: план обучения или найм специалистов

**❓ Вопросы для уточнения:**

1. Каков текущий объём данных? (количество участников, документов, транзакций/день)
2. Какой бюджет на инфраструктуру на ближайшие 12 месяцев?
3. Есть ли в команде Data Engineer или Web3 Developer?
4. Насколько критична портативность профилей? (можем ли начать без блокчейна?)
5. Какие внешние системы уже используются? (CRM, клубная платформа, что ещё?)
6. Требуется ли real-time персонализация или достаточно batch-обновлений раз в час/день?
7. Планируется ли открытие API для сторонних разработчиков агентов?

**🔍 Что стоит изучить дальше:**

- Аудит текущих систем: какие данные уже есть, в каких форматах
- Прототипирование векторного поиска на малой выборке документов
- Оценка стоимости managed services (Pinecone, Neo4j Aura, Supabase vs self-hosted)
- Консультация с Web3 экспертами о целесообразности блокчейна на текущей стадии

---

**Финальная рекомендация:** Начните с **Варианта 1 (Docs-first)** + постепенное добавление элементов Варианта 2 (PostgreSQL для профилей, векторный поиск). Вариант 3 оставьте на будущее, когда токеномика станет ключевой и появится запрос на портативность.
